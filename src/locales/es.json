{
  "header": {
    "title": "√Årbol de Decisi√≥n",
    "home": "Inicio",
    "language": "üåê Idioma",
    "theme": {
      "dark": "üåô Oscuro",
      "light": "‚òÄÔ∏è Claro"
    }
  },
  "hero": {
    "title": "Explorando el mundo de los √Årboles de Decisi√≥n",
    "subtitle": "Una introducci√≥n visual al aprendizaje autom√°tico"
  },
  "section-understanding": {
    "title": "Entendiendo √Årboles de Decisi√≥n y Poda",
    "intro": {
      "welcome": "Bienvenido a nuestra {guide} ‚Äî una de las herramientas m√°s {powerful} en el campo de la inteligencia artificial y la ciencia de datos.",
      "guide": "gu√≠a interactiva sobre √°rboles de decisi√≥n",
      "powerful": "intuitivas y poderosas",
      "purpose": "Este sitio fue creado para ayudarte a comprender, de forma {visual}, c√≥mo funcionan estas estructuras, c√≥mo se construyen, y por qu√© son tan √∫tiles para resolver problemas de {classification} y {regression}.",
      "visual": "visual y accesible",
      "classification": "clasificaci√≥n",
      "regression": "regresi√≥n",
      "pruning": "Adem√°s, exploraremos un concepto esencial para mejorar el rendimiento de los √°rboles: {pruningConcept}. Reduce la complejidad del modelo, evita el {overfitting} (sobreajuste) y hace que las predicciones sean m√°s confiables con datos nuevos.",
      "pruningConcept": "la poda",
      "overfitting": "overfitting",
      "conclusion": "Aqu√≠ encontrar√°s {clear}, {visual_examples} y {demonstrations} para construir y optimizar √°rboles de decisi√≥n. Ya seas principiante o tengas experiencia, nuestro objetivo es hacer que estos conceptos sean simples, interactivos y aplicables.",
      "clear": "explicaciones claras",
      "visual_examples": "ejemplos visuales",
      "demonstrations": "demostraciones paso a paso"
    }
  },
  "section-what-is": {
    "title": "¬øQu√© es?",
    "definition": "Un {decision_tree} es un modelo predictivo que representa una serie de decisiones estructuradas en forma de √°rbol, donde cada {internal_node} corresponde a una pregunta o condici√≥n basada en las caracter√≠sticas de los datos, y cada {branch} lleva a una posible respuesta o divisi√≥n. Las {leaves} del √°rbol indican el resultado final, como una clase o valor num√©rico. Este modelo es ampliamente utilizado en tareas de {classification} y {regression} debido a su interpretaci√≥n intuitiva: simula un proceso de toma de decisiones secuencial, donde seguimos un camino l√≥gico basado en las entradas hasta llegar a una conclusi√≥n.",
    "decision_tree": "√°rbol de decisi√≥n",
    "internal_node": "nodo interno",
    "branch": "rama",
    "leaves": "hojas",
    "classification": "clasificaci√≥n",
    "regression": "regresi√≥n"
  },

  "section-dataset": {
    "title": "Acerca del conjunto de datos utilizado",
    "paragraph1": "El conjunto de datos original contiene informaci√≥n sobre viviendas en distritos espec√≠ficos de California, con estad√≠sticas resumidas basadas en los datos del censo de 1990. Para el prop√≥sito espec√≠fico de nuestra visualizaci√≥n ‚Äîque se centra en la <b>clasificaci√≥n de viviendas entre Sacramento y San Francisco</b>‚Äî realizamos una selecci√≥n y transformaci√≥n de las variables. El objetivo era centrarse en las caracter√≠sticas intr√≠nsecas de la vivienda y su ubicaci√≥n para la tarea de clasificaci√≥n binaria.",
    "paragraph2": "En consecuencia, se eliminaron las variables que no contribu√≠an directamente a la descripci√≥n de las caracter√≠sticas de la propiedad o que resultaban redundantes para la clasificaci√≥n geogr√°fica tras la introducci√≥n de la variable <code>city</code>.",
    "variables_intro": "Las variables utilizadas en nuestra visualizaci√≥n son:",
    "variables": {
      "total_rooms": "<b>total rooms</b>: Representa el n√∫mero total de habitaciones dentro de una manzana. Esta variable ayuda a entender el tama√±o o la capacidad de una propiedad.",
      "total_bedrooms": "<b>total bedrooms</b>: Indica el n√∫mero total de dormitorios dentro de una manzana. Complementa a <i>total rooms</i> proporcionando una medida m√°s espec√≠fica de la composici√≥n de la vivienda.",
      "households": "<b>households</b>: Corresponde al n√∫mero total de hogares que residen en unidades habitacionales dentro de una manzana. Ofrece contexto sobre la densidad poblacional y el uso de las propiedades.",
      "median_house_value": "<b>median house value</b>: Se refiere al valor medio de las viviendas dentro de una manzana, medido en d√≥lares estadounidenses. Aunque no es la variable objetivo de nuestra clasificaci√≥n, es un indicador socioecon√≥mico relevante que puede estar correlacionado con la ubicaci√≥n.",
      "city": "<b>city</b>: Es la variable objetivo creada para nuestro problema de clasificaci√≥n. Indica si una vivienda est√° ubicada en <b>Sacramento</b> o en <b>San Francisco</b>."
    },
    "paragraph3": "Esta selecci√≥n permiti√≥ que la visualizaci√≥n se centrara en las relaciones entre las caracter√≠sticas de las viviendas y su clasificaci√≥n geogr√°fica."
  },

  "section-prediction": {
    "title": "C√≥mo funciona la predicci√≥n en un √°rbol de decisi√≥n",
    "description": "Durante el proceso de {prediction}, el √°rbol de decisi√≥n recibe una nueva entrada (o muestra) y la recorre desde el {root_to_leaf}, siguiendo las condiciones definidas en cada punto de decisi√≥n. En cada etapa, analiza el valor de una {feature} de la entrada y elige la {corresponding_branch} bas√°ndose en la condici√≥n (por ejemplo, si el valor es menor o mayor que un cierto l√≠mite). Este camino es {unique} y lleva directamente hasta una {leaf}, donde se registra la clase predicha (en clasificadores) o un valor num√©rico (en modelos de regresi√≥n). El proceso es {fast_interpretable}, funcionando como una secuencia l√≥gica de decisiones que culmina en una conclusi√≥n final.",
    "prediction": "predicci√≥n",
    "root_to_leaf": "nodo ra√≠z hasta una hoja",
    "feature": "caracter√≠stica",
    "corresponding_branch": "rama correspondiente",
    "unique": "√∫nico",
    "leaf": "hoja",
    "fast_interpretable": "r√°pido, directo e interpretable"
  },
  "section-gini": {
    "title": "¬øC√≥mo se eligen los cortes?",
    "description": "En un √°rbol de decisi√≥n para clasificaci√≥n binaria, los cortes se eligen bas√°ndose en la {purity} de las regiones creadas despu√©s de cada divisi√≥n.",
    "purity": "pureza",
    "purity_explanation": "La pureza de una regi√≥n es una medida de qu√© tan homog√©neas son las clases dentro de ella. Si todos los ejemplos en una regi√≥n pertenecen a la misma clase, esa regi√≥n se considera pura. Para cuantificar esta pureza, usamos m√©tricas como la {entropy} (H) y el {gini_index} (G).",
    "entropy": "Entrop√≠a",
    "gini_index": "√çndice Gini",
    "metrics_behavior": "Estas m√©tricas alcanzan sus valores m√≠nimos (cero) cuando todos los ejemplos son de la misma clase (proporci√≥n 0 o 1), y valores m√°ximos cuando hay equilibrio entre las clases (proporci√≥n 0.5), es decir, cuando la incertidumbre es mayor. El algoritmo calcula la ganancia de pureza antes y despu√©s de cada posible divisi√≥n ‚Äî llamada {information_gain} (con entrop√≠a) o {gini_gain} ‚Äî y elige el corte que m√°s aumenta esta ganancia.",
    "information_gain": "Ganancia de Informaci√≥n",
    "gini_gain": "Ganancia de Gini",
    "process_conclusion": "Este proceso se repite recursivamente, creando una segmentaci√≥n binaria del espacio, hasta que se alcanza un criterio de parada, como el n√∫mero m√≠nimo de puntos por regi√≥n.",
    "interaction_hint": "Pasa el mouse sobre el gr√°fico para ver los valores espec√≠ficos de entrop√≠a y Gini para cada proporci√≥n de clase positiva.",
    "chart_labels": {
      "x_axis": "Proporci√≥n de la clase positiva (p)",
      "y_axis": "Pureza (Entrop√≠a o Gini)",
      "entropy_legend": "Entrop√≠a",
      "gini_legend": "Gini",
      "entropy_tooltip": "Entrop√≠a: {value}",
      "gini_tooltip": "Gini: {value}"
    }
  },
  "cutoffs": {
    "title": "Visualizaci√≥n de los cortes individualmente",
    "paragraph": "Una forma de ver estos cortes es proyectando sobre una variable para observar c√≥mo ocurre la distribuci√≥n univariada y cortar en el punto donde las clases est√°n mejor separadas.",
    "paragraph2": "<p>La elecci√≥n del mejor punto de corte en un √°rbol de decisi√≥n se realiza evaluando, para cada valor posible de la variable, c√≥mo la divisi√≥n de los datos impacta en la pureza de los grupos formados. En el gr√°fico de arriba, la distribuci√≥n de los datos se muestra como un histograma, separado por clases (San Francisco y Sacramento). La l√≠nea discontinua representa el punto de corte seleccionado ‚Äî aquel que genera la menor <strong>impureza ponderada</strong> entre los dos lados (izquierda y derecha).<br><br>Matem√°ticamente, esta elecci√≥n se realiza minimizando la siguiente funci√≥n de impureza ponderada:</p>",
    "paragraph3": "<p>Donde:<br>‚Äì <strong>N<sub>izq</sub></strong> y <strong>N<sub>der</sub></strong> son el n√∫mero de muestras en los grupos de la izquierda y la derecha despu√©s del corte.<br>‚Äì <strong>N<sub>total</sub></strong> es el n√∫mero total de muestras antes del corte.<br>‚Äì <strong>Impureza<sub>izq</sub></strong> y <strong>Impureza<sub>der</sub></strong> son las impurezas calculadas en cada lado, que pueden medirse por <em>√çndice de Gini</em>, <em>Entrop√≠a</em> u otra m√©trica.<br><br>Debajo del histograma, los gr√°ficos de impureza indican c√≥mo var√≠a a lo largo de los posibles valores de corte: las l√≠neas de impureza izquierda y derecha muestran cu√°n homog√©neos son los grupos tras cada posible divisi√≥n. El punto de corte elegido es aquel donde la impureza ponderada alcanza su valor m√°s bajo, buscando la separaci√≥n m√°s eficiente entre las clases.<br>Modifique el corte para ver el cambio de impurezas:</p>",
    "feature_label": "Caracter√≠stica {number}",
    "characteristic": "Caracter√≠stica:",
    "value_range": "Rango de valores:",
    "cutoff_point": "Punto de corte:",
    "loading": "Cargando...",
    "loading_data": "Cargando datos...",
    "error_loading": "‚ùå Error al cargar los datos",
    "city_comparison": "Sacramento (p√∫rpura) vs San Francisco (verde)",
    "steps": {
      "total_rooms": {
        "title": "Total de Habitaciones",
        "description": "Esta variable representa el n√∫mero total de habitaciones en todas las viviendas de una manzana. Es una m√©trica que refleja, de forma agregada, el tama√±o de las propiedades en esa √°rea. Las manzanas con m√°s habitaciones suelen indicar casas m√°s grandes o una mayor densidad de viviendas. Esta caracter√≠stica es relevante para el modelo porque ayuda a identificar patrones en el mercado inmobiliario. En el gr√°fico, puedes observar c√≥mo se distribuye esta variable y c√≥mo definimos un punto de corte que mejor separa las clases, convirtiendo esta caracter√≠stica continua en una divisi√≥n binaria m√°s interpretable.",
        "axis_label": "Total de Habitaciones"
      },
      "total_bedrooms": {
        "title": "Total de Dormitorios",
        "description": "Esta variable indica el n√∫mero total de dormitorios dentro de una manzana. Complementa 'Total de Habitaciones' al proporcionar una medida m√°s espec√≠fica sobre la composici√≥n de las propiedades. Es una caracter√≠stica importante para determinar la capacidad habitacional de las viviendas. Esta variable ofrece informaci√≥n valiosa sobre el espacio funcional destinado a la vida residencial.",
        "axis_label": "Total de Dormitorios"

      },
      "households": {
        "title": "Total de Hogares",
        "description": "Indica el n√∫mero total de hogares ‚Äî definidos como grupos de personas que residen en una misma unidad habitacional ‚Äî dentro de una manzana. Esta variable refleja la estructura residencial de la zona y es un indicador clave de la densidad poblacional y las caracter√≠sticas del vecindario. Las manzanas con un mayor n√∫mero de hogares pueden reflejar √°reas m√°s densamente pobladas o con mayor subdivisi√≥n residencial.",
        "axis_label": "Total de Hogares"

      },
      "median_house_value": {
        "title": "Valor Mediano de las Casas",
        "description": "Esta caracter√≠stica representa el valor mediano de las casas en la regi√≥n. Es una caracter√≠stica econ√≥mica importante que refleja el mercado inmobiliario local. Esta caracter√≠stica captura informaci√≥n sobre el poder adquisitivo y patr√≥n socioecon√≥mico del √°rea donde se encuentra ubicada la propiedad.",
        "axis_label": "Valor Mediano (USD)"
      }
    }
  },
  "scatterplot": {
    "frequency": "Frecuencia",
    "value": "Valor",
    "cutoff_tooltip": "valor < {value}",
    "point_tooltip": {
      "property_of": "Propiedad de {city}",
      "value": "Valor: {value}",
      "frequency": "Frecuencia: ~{frequency} propiedades similares",
      "below_cutoff": "Debajo del punto de corte",
      "above_cutoff": "Encima del punto de corte"
    }
  },
  "page": {
    "testTitle": "P√°gina de Prueba",
    "step": "Paso {number}",
    "stage": "Etapa {number}"
  },
  "scroll": {
    "block1": {
      "title": "Etapa {number}",
      "content": "Texto para la etapa {number}. Lorem ipsum dolor sit amet consectetur adipisicing elit."
    },
    "block2": {
      "title": "Bloque 2 - Etapa {number}",
      "content": "Contenido diferente para el bloque 2 - etapa {number}. Lorem ipsum dolor sit amet consectetur adipisicing elit."
    }
  },
  "section-tree-creation": {
    "title": "Creaci√≥n del √Årbol y Cortes en el Espacio de Datos",
    "description": "La creaci√≥n del √°rbol de decisi√≥n consiste en dividir repetidamente el espacio de los datos en regiones m√°s peque√±as por medio de {cuts} sobre las caracter√≠sticas. Cada corte separa los datos en grupos m√°s homog√©neos, facilitando la toma de decisiones. Este proceso contin√∫a hasta que las regiones est√©n suficientemente puras o se alcance un criterio de parada, resultando en una estructura jer√°rquica que refleja estas divisiones en el espacio.",
    "cuts": "cortes basados en condiciones"
  },
  "section-interactive-prediction": {
    "title": "C√≥mo funciona la predicci√≥n en un √°rbol de decisi√≥n",
    "practice_text": "Para ver esto en la pr√°ctica, elige un valor para cada variable y observa cu√°l ser√° la predicci√≥n en este √°rbol ya construido anteriormente:",
    "loading_tree": "Cargando √°rbol de decisi√≥n...",
    "interactive_placeholder": "Aqu√≠ ir√° un √°rbol interactivo, donde construimos un dato y vemos recorrer el √°rbol hasta la predicci√≥n"
  },
  "section-complete-tree": {
    "title": "El √Årbol Completo",
    "description": "Un √°rbol de decisi√≥n que crece completamente contin√∫a realizando divisiones en el espacio de los datos hasta que cada hoja contenga solo ejemplos de una √∫nica clase, alcanzando as√≠ {accuracy} en el conjunto de entrenamiento. Aunque este modelo memoriza perfectamente los datos, tiende a ser muy complejo y espec√≠fico, lo que puede llevar al {overfitting}, es decir, a una menor capacidad de generalizar para datos nuevos y no vistos.",
    "accuracy": "100% de precisi√≥n",
    "overfitting": "sobreajuste",
    "example_text": "Ve abajo c√≥mo quedar√≠a el √°rbol completo generado con todas las caracter√≠sticas de nuestros datos de ejemplo"
  },
  "pruning": {
    "title": "M√©todos de Poda de √Årboles de Decisi√≥n",
    "description": "Selecciona un m√©todo de poda para ver c√≥mo afecta la estructura del √°rbol de decisi√≥n",
    "selected_method": "M√©todo Seleccionado:",
    "loading": "Cargando √°rbol de decisi√≥n...",
    "error": "Error al cargar el √°rbol. Por favor, intenta seleccionar otro m√©todo de poda.",
    "accuracy": "Precisi√≥n:",
    "nodes": "Nodos:",
    "depth": "Profundidad:",
    "methods": {
      "original": {
        "name": "Sin Poda",
        "description": "√Årbol completo sin podas aplicadas"
      },
      "validacao": {
        "name": "Poda por Validaci√≥n",
        "description": "Poda basada en mejora de precisi√≥n en validaci√≥n"
      },
      "profundidade_3": {
        "name": "Poda por Profundidad (3)",
        "description": "Limita la profundidad m√°xima a 3 niveles"
      },
      "profundidade_4": {
        "name": "Poda por Profundidad (4)",
        "description": "Limita la profundidad m√°xima a 4 niveles"
      },
      "custo_complexidade_001": {
        "name": "Costo-Complejidad (Œ±=0.01)",
        "description": "Poda por costo-complejidad con Œ±=0.01"
      },
      "hibrida": {
        "name": "Poda H√≠brida",
        "description": "Combina m√∫ltiples criterios de poda"
      }
    }
  },
  "footer": {
    "developed_by": "Desarrollado por Paula Eduarda de Lima, Mariana Fernandes Rocha y Joel Perca con SvelteKit & D3.js"
  },
  "step3": {
    "steps": [
        {
          "title": "Sin Divisiones",
          "content": "El √°rbol clasifica todas las regiones seg√∫n la clase m√°s frecuente. Antes de realizar cualquier divisi√≥n, la clasificaci√≥n ser√≠a 'San Francisco', que es la clase m√°s com√∫n en los datos."
        },
        {
          "title": "Profundidad 0 ‚Äî Ra√≠z del √Årbol",
          "content": "En la parte superior del √°rbol, tenemos la primera decisi√≥n basada en la condici√≥n <code>feature 1 ‚â§ 185300</code>. Esta divisi√≥n separa los datos en dos grandes grupos. Los colores indican la clase asignada a cada regi√≥n respectiva."
        },
        {
          "title": "Profundidad 1 ‚Äî Primera Divisi√≥n de las Ramas",
          "content": "En este nivel, cada grupo generado por la divisi√≥n anterior se analiza por separado. El √°rbol aplica nuevas divisiones dentro de cada grupo, creando subdivisiones m√°s espec√≠ficas. Este proceso refleja la naturaleza recursiva de los √°rboles de decisi√≥n: cada rama se trata como un nuevo subproblema, donde el algoritmo busca localmente la mejor divisi√≥n para reducir la impureza."
        },
        {
          "title": "Profundidad 2 ‚Äî Ramificaciones Detalladas",
          "content": "A continuaci√≥n, aparecen nuevas divisiones, como <code>feature 1 ‚â§ 72600</code>. El algoritmo sigue probando todos los puntos de corte posibles en todas las variables disponibles y elige aquel que proporciona la mayor ganancia de informaci√≥n. Esta ganancia se calcula en funci√≥n de una m√©trica de impureza, como la entrop√≠a o el √≠ndice de Gini, que exploraremos en las siguientes etapas."
        },
        {
          "title": "Profundidad 3 ‚Äî Divisiones Ortogonales",
          "content": "Los √°rboles de decisi√≥n realizan divisiones ortogonales en el espacio de atributos, lo que significa que cada corte considera solo una variable a la vez, trazando una l√≠nea recta (o un plano en dimensiones superiores) perpendicular al eje de la variable seleccionada. Esto crea fronteras de decisi√≥n en forma de rect√°ngulos en un espacio bidimensional o hiper-rect√°ngulos (hipercajas) en espacios de mayor dimensi√≥n. Este tipo de partici√≥n funciona bien cuando los datos tienen patrones alineados con los ejes, pero puede ser limitante si las fronteras naturales son curvas o diagonales."
        },
        {
          "title": "Profundidad 4 ‚Äî Estabilidad",
          "content": "Los √°rboles son modelos de alta varianza: peque√±os cambios en los datos pueden generar √°rboles completamente diferentes. Por esta raz√≥n, se han desarrollado t√©cnicas como Random Forests o Boosting para mejorar la robustez y reducir la varianza."
        },
        {
          "title": "Profundidad 5 ‚Äî Hojas del √Årbol",
          "content": "Las hojas del √°rbol corresponden a las predicciones finales del modelo: \"Sacramento\" o \"San Francisco\". Cada hoja representa una regi√≥n del espacio de atributos donde el modelo toma una decisi√≥n. Visualmente, el color de cada rect√°ngulo indica la clase asignada a esa regi√≥n. Cualquier punto que caiga dentro de una de estas √°reas ser√° clasificado seg√∫n el color correspondiente, reflejando la clase mayoritaria en esa subdivisi√≥n."
        },
        {
          "title": "Profundidad 6 ‚Äî Datos Interesantes",
          "content": "Los √°rboles de decisi√≥n no se limitan a tareas de clasificaci√≥n; tambi√©n se pueden utilizar para problemas de regresi√≥n. En este caso, el valor predicho en cada hoja es el promedio de los valores objetivo de las muestras en ese nodo. El criterio de divisi√≥n suele ser el error cuadr√°tico medio (MSE)."
        },
        {
          "title": "Profundidad 7 ‚Äî Interpretaci√≥n Visual",
          "content": "La estructura jer√°rquica del √°rbol es altamente interpretable, lo que la hace ideal para aplicaciones educativas, legales, m√©dicas y empresariales donde las decisiones deben ser comprensibles y justificables."
        },
        {
          "title": "Profundidad 8 ‚Äî Crecimiento Recursivo",
          "content": "La construcci√≥n de un √°rbol de decisi√≥n sigue un proceso recursivo de divisi√≥n. En cada paso, el algoritmo considera solo los datos que han llegado a ese nodo y elige la mejor divisi√≥n basada en una m√©trica de impureza. Esto permite que cada rama se especialice en una parte espec√≠fica del espacio de atributos, adapt√°ndose progresivamente a los patrones observados. Este crecimiento contin√∫a hasta que se cumplen uno o m√°s criterios de parada, como la profundidad m√°xima, el n√∫mero m√≠nimo de muestras por nodo o la pureza total de las hojas."
        },
        {
          "title": "Profundidad 9 ‚Äî Criterios de Parada",
          "content": "El crecimiento del √°rbol no es infinito. Se detiene cuando se cumple uno o m√°s criterios de parada. Esto puede suceder cuando: (1) el nodo se vuelve puro, es decir, todas las muestras pertenecen a la misma clase; (2) el n√∫mero de muestras en el nodo es menor que un umbral m√≠nimo predefinido; (3) se alcanza la profundidad m√°xima del √°rbol, definida por el usuario; o (4) no hay una ganancia significativa de informaci√≥n al realizar nuevas divisiones. Estos criterios controlan la complejidad del modelo y ayudan a prevenir el sobreajuste."
        },
        {
          "title": "Profundidad 10 ‚Äî Sobreajuste",
          "content": "Si no se aplican restricciones, el √°rbol continuar√° dividiendo los datos hasta que cada hoja contenga solo una muestra, logrando un 100% de precisi√≥n en el conjunto de entrenamiento. Sin embargo, esto suele conducir al sobreajuste, donde el modelo se ajusta demasiado a los datos vistos y pierde la capacidad de generalizar a datos nuevos. Por eso, t√©cnicas como la poda (pruning) son esenciales para limitar la complejidad y mejorar el rendimiento predictivo."
        }
      ],
    "step_not_available": "Etapa {number} no disponible."
  },
  "about": {
    "title": "Acerca de",
    "presentation-title": "Presentaci√≥n",
    "presentation-text": "En la pesta√±a de Inicio, encontrar√°s nuestra visualizaci√≥n interactiva que gu√≠a la explicaci√≥n del funcionamiento del algoritmo de √°rbol de decisi√≥n. Adem√°s de mostrar la estructura del √°rbol, ofrecemos visualizaciones din√°micas que ayudan a comprender el proceso de construcci√≥n del √°rbol, permitiendo entender c√≥mo se eligen las divisiones.",
    "resume-title": "Resumen del Proyecto",
    "resume-text": "La plataforma presenta ",
    "modules": "m√≥dulos visuales e interactivos ",
    "resume-text2": "que facilitan la comprensi√≥n de los ",
    "models": "modelos basados en √°rboles binarios.",
    "images": "Vistas del modelo",
    "list-title": "Entre las principales funcionalidades est√°n:",
    "item1": "Construcci√≥n din√°mica del √°rbol de decisi√≥n junto con los cortes en el espacio 2D de los datos",
    "item2": "Simulaciones de predicci√≥n interactivas",
    "item3": "Gr√°ficos de las m√©tricas de impureza (√çndice de Gini y Entrop√≠a)",
    "item4": "Histogramas que ilustran los cortes univariados",
    "item5": "Dendrograma que ilustra la poda manual de √°rboles complejos",
    "item6": "Opciones completas de √°rbol y poda, lo que le permite comparar diferentes m√©todos para simplificar la estructura.", 
    "accessibility": "El proyecto tambi√©n fue desarrollado con enfoque en accesibilidad y personalizaci√≥n, incluyendo:",
    "acc-list1": "Soporte multiling√ºe (Portugu√©s, Espa√±ol e Ingl√©s)",
    "acc-list2": "Alternancia entre temas claro y oscuro",
    "article-title": "Art√≠culo",
    "click": "Haz clic aqu√≠",
    "article-text": " para acceder al art√≠culo completo",
    "video-title": "Video de Presentaci√≥n",
    "team-members": "Miembros del Equipo",
    "instructions-title": "Instrucciones de Ejecuci√≥n",
    "instructions-text": "Este proyecto fue creado usando",
    "local-run": ". Para ejecutarlo localmente:",
    "run-step1": "Clona el repositorio disponible en la pesta√±a 'GitHub' en este sitio.",
    "run-step2": "Instala las dependencias con ",
    "run-step3": "Ejecuta el servidor de desarrollo con ",
    "run-step4": "Accede en el navegador",
    "run-step5": "(o el puerto indicado en la terminal)"
  }
}
